{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1deb9ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing memory from 'user_memory.txt'.\n"
     ]
    }
   ],
   "source": [
    "from langgraph_supervisor import create_supervisor\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Annotated, Sequence, TypedDict, Optional,Literal\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph import add_messages\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage,ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "import json\n",
    "import os\n",
    "from langgraph.managed import RemainingSteps\n",
    "from langgraph.graph import START, StateGraph, END \n",
    "from IPython.display import Image, display\n",
    "from langgraph.prebuilt import ToolNode\n",
    "    \n",
    "import requests\n",
    "\n",
    "#1. light, TV, ve general devices \n",
    "PowerStatus = Literal[\"on\", \"off\", \"unknown\"]\n",
    "powerAction = Literal[\"on\", \"off\"]\n",
    "\n",
    "# 2.(Door)\n",
    "LockStatus = Literal[\"locked\", \"unlocked\", \"unknown\"]\n",
    "LockAction = Literal[\"lock\", \"unlock\"]\n",
    "\n",
    "# 3. Perde ve Vana için\n",
    "OpenCloseStatus = Literal[\"open\", \"closed\", \"unknown\"]\n",
    "OpenCloseAction = Literal[\"open\", \"close\"]\n",
    "\n",
    "# (Curtains)\n",
    "#MotionStatus = Literal[\"open\", \"closed\", \"opening\", \"closing\", \"stopped\", \"unknown\"]\n",
    "\n",
    "# (AC, Heater)\n",
    "\n",
    "#HvacStatus = Literal[\"off\", \"cool\", \"heat\", \"fan_only\", \"auto\", \"unknown\"]\n",
    "#HvacAction = Literal[\"set_mode_off\", \"set_mode_cool\", \"set_mode_heat\", \"set_mode_fan_only\", \"set_mode_auto\"]\n",
    "\n",
    "HvacStatus = Literal[\"off\",\"unknown\"]\n",
    "HvacAction = Literal[\"set_mode_off\", \"set_mode_on\"]\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    light: PowerStatus\n",
    "    door_lock: LockStatus\n",
    "    curtain: OpenCloseStatus\n",
    "    tv: PowerStatus\n",
    "    #termostat and AC combined\n",
    "    thermostat_mode: HvacStatus\n",
    "    main_water_valve: OpenCloseStatus\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    remaining_steps: RemainingSteps\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "user_memory_file = \"user_memory.txt\"\n",
    "memory = \"\"\n",
    "\n",
    "try:\n",
    "    # Check if the file exists\n",
    "    if os.path.exists(user_memory_file):\n",
    "        # If the file exists, open it in 'r' (read) mode\n",
    "        with open(user_memory_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            memory = f.read()\n",
    "        print(f\"Loaded existing memory from '{user_memory_file}'.\")\n",
    "    else:\n",
    "        print(f\"'{user_memory_file}' file not found. Initializing memory as empty.\")\n",
    "        \n",
    "except IOError as e:\n",
    "    print(f\"File read error: {e}. Initializing memory as empty.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred (reading): {e}. Initializing memory as empty.\")\n",
    "\n",
    "\n",
    "\n",
    "rules_content = \"{}\"\n",
    "try:\n",
    "    if os.path.exists(\"rules_operations.json\"):\n",
    "        with open(\"rules_operations.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            operations_list = data.get(\"operations\", [])\n",
    "            formatted_modes = {}\n",
    "            for item in operations_list:\n",
    "                name = item.get(\"operation_name\")\n",
    "                actions = item.get(\"home_operations\", [])\n",
    "                if name and actions:\n",
    "                    formatted_modes[name] = actions\n",
    "            if formatted_modes:\n",
    "                rules_content = json.dumps(formatted_modes,ensure_ascii=False, indent=2)\n",
    "    else:\n",
    "        print(\"rules_operations.json file not found. Using empty rules.\")\n",
    "        default_data = {\n",
    "            \"rules\":[],\n",
    "            \"operations\":[]\n",
    "        }\n",
    "        with open(\"rules_operations.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(default_data, f, ensure_ascii=False, indent=2)\n",
    "except Exception as e:\n",
    "    print(f\"Home Agent Warning: Could not read rules file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ce79826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'light': 'off',\n",
       " 'tv': 'off',\n",
       " 'curtain': 'closed',\n",
       " 'door_lock': 'locked',\n",
       " 'thermostat_mode': 'off',\n",
       " 'main_water_valve': 'closed'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"home_status.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    HOME_DB = json.load(f)\n",
    "\n",
    "HOME_DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "253c045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_state():\n",
    "    \"\"\"Fetch the initial state from the local server.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(\"http://127.0.0.1:8000/status\")\n",
    "        current_state = response.json()\n",
    "        \n",
    "        print(\"Current Home State:\")\n",
    "        for device, state in current_state.items():\n",
    "            print(f\"  - {device}: {state}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(\"Could not connect to server. Is main.py running?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae4e05f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_home_db(device_id: str, value: str):\n",
    "    \"\"\"Update the HOME_DB with the new device state.\"\"\"\n",
    "    \n",
    "    if device_id in HOME_DB:\n",
    "        HOME_DB[device_id] = value\n",
    "    else:\n",
    "        # Eşleşmeyen isimler için (örn: main_thermostat -> thermostat_mode) manuel map\n",
    "        if \"thermostat\" in device_id: HOME_DB[\"thermostat_mode\"] = value\n",
    "        if \"door\" in device_id: HOME_DB[\"door_lock\"] = value\n",
    "        # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1a17ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_db():\n",
    "    \"\"\"Saves the current notebook state to a file.\"\"\"\n",
    "    with open(\"home_status.json\", \"w\") as f:\n",
    "        json.dump(HOME_DB, f)\n",
    "    print(\"Database synced to home_status.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cced104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To run this code, please ensure that the home automation API server is running at localhost:8000.\n",
      "Or you can continue without api connection for testing purposes.\n"
     ]
    }
   ],
   "source": [
    "API_URL = \"http://localhost:8000\"\n",
    "try:\n",
    "    requests.post(f\"{API_URL}/update_device\", json={\n",
    "        \"device_id\": \"thermostat_mode\",\n",
    "        \"action\": \"set_mode_off\"\n",
    "    })\n",
    "except Exception as e:\n",
    "    print(\"To run this code, please ensure that the home automation API server is running at localhost:8000.\")\n",
    "    print(\"Or you can continue without api connection for testing purposes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4874c1",
   "metadata": {},
   "source": [
    "# 1.Home System Agent(SubAgent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1553b262",
   "metadata": {},
   "source": [
    "## Light Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50ad7014",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def control_light(device_id: str, action: powerAction) -> str:\n",
    "    \"\"\"\n",
    "    Controls a light fixture by turning it 'on' or 'off'.\n",
    "    This tool *only* sends the command; it does not check the current state.\n",
    "\n",
    "    Args:\n",
    "        device_id (str): The identifier for the light (e.g., 'living_room_light', 'kitchen_light').\n",
    "        action (powerAction): The desired action, must be 'on' or 'off'.\n",
    "\n",
    "    Returns:\n",
    "        str: A JSON formatted string containing 'device_id', 'action', and a 'message'.\n",
    "    \"\"\"\n",
    "    print(f\"\\n*** TOOL WORKED: control_light(device_id={device_id}, action={action}) ***\")\n",
    "    \n",
    "    payload = {\n",
    "        'device_id': device_id,\n",
    "        'action': action\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(f\"{API_URL}/update_device\", json=payload)\n",
    "        if response.status_code == 200:\n",
    "\n",
    "            result_data = {\n",
    "                \"device_id\": device_id,\n",
    "                \"action\": action,\n",
    "                \"message\": f\"I have turned {action} the {device_id}.\",\n",
    "                \"api_response\": \"success\"\n",
    "            }\n",
    "        else:\n",
    "            result_data = {\n",
    "                \"device_id\": device_id,\n",
    "                \"action\": action,\n",
    "                \"message\": f\"I have turned {action} the {device_id}.\",\n",
    "                \"api_response\": \"failure\",\n",
    "            }\n",
    "    except Exception:\n",
    "        result_data = {\n",
    "        \"device_id\": device_id,\n",
    "        \"action\": action,\n",
    "        \"message\": f\"I have turned {action} the {device_id}.\"\n",
    "    }\n",
    "\n",
    "    return json.dumps(result_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eccdd6a",
   "metadata": {},
   "source": [
    "## Door Lock Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef8537ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def control_lock(device_id: str, action: LockAction) -> str:\n",
    "    \"\"\"\n",
    "    Controls a door lock by setting it to 'lock' or 'unlock'.\n",
    "    This tool *only* sends the command; it does not check the current state.\n",
    "\n",
    "    Args:\n",
    "        device_id (str): The identifier for the lock (e.g., 'front_door_lock').\n",
    "        action (LockAction): The desired action, must be 'lock' or 'unlock'.\n",
    "\n",
    "    Returns:\n",
    "        str: A JSON formatted string containing 'device_id', 'action', and a 'message'.\n",
    "    \"\"\"\n",
    "    print(f\"\\n*** TOOL WORKED: control_lock(device_id={device_id}, action={action}) ***\")\n",
    "    \n",
    "    action_val = action.value if hasattr(action, \"value\") else str(action)\n",
    "    \n",
    "    if action_val == \"lock\":\n",
    "        message = f\"I have locked the {device_id}.\"\n",
    "    else:\n",
    "        message = f\"I have unlocked the {device_id}.\"\n",
    "\n",
    "\n",
    "    payload = {\n",
    "        'device_id': device_id,\n",
    "        'action': action\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(f\"{API_URL}/update_device\", json=payload)\n",
    "        if response.status_code == 200:\n",
    "\n",
    "            result_data = {\n",
    "                \"device_id\": device_id,\n",
    "                \"action\": action,\n",
    "                \"message\": message,\n",
    "                \"api_response\": \"success\"\n",
    "            }\n",
    "        else:\n",
    "            result_data = {\n",
    "                \"device_id\": device_id,\n",
    "                \"action\": action,\n",
    "                \"message\": message,\n",
    "                \"api_response\": \"failure\",\n",
    "            }\n",
    "    except Exception:\n",
    "        result_data = {\n",
    "        \"device_id\": device_id,\n",
    "        \"action\": action,\n",
    "        \"message\": message\n",
    "    }\n",
    "\n",
    "    return json.dumps(result_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c516033",
   "metadata": {},
   "source": [
    "## Curtain Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2248bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def control_curtain(device_id: str, action: OpenCloseAction) -> str:\n",
    "    \"\"\"\n",
    "    Controls curtains or blinds by setting them to 'open' or 'close'.\n",
    "    This tool *only* sends the command; it does not check the current state.\n",
    "\n",
    "    Args:\n",
    "        device_id (str): The identifier for the curtain (e.g., 'living_room_curtain').\n",
    "        action (OpenCloseAction): The desired action, must be 'open' or 'close'.\n",
    "\n",
    "    Returns:\n",
    "        str: A JSON formatted string containing 'device_id', 'action', and a 'message'.\n",
    "    \"\"\"\n",
    "    print(f\"\\n*** TOOL WORKED: control_curtain(device_id={device_id}, action={action}) ***\")\n",
    "    if action == \"open\":\n",
    "        message = f\"I have opened the {device_id}.\"\n",
    "    else:\n",
    "        message = f\"I have closed the {device_id}.\"\n",
    "    \n",
    "    payload = {\n",
    "        'device_id': device_id,\n",
    "        'action': action\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(f\"{API_URL}/update_device\", json=payload)\n",
    "        if response.status_code == 200:\n",
    "\n",
    "            result_data = {\n",
    "                \"device_id\": device_id,\n",
    "                \"action\": action,\n",
    "                \"message\": message,\n",
    "                \"api_response\": \"success\"\n",
    "            }\n",
    "        else:\n",
    "            result_data = {\n",
    "                \"device_id\": device_id,\n",
    "                \"action\": action,\n",
    "                \"message\": message,\n",
    "                \"api_response\": \"failure\",\n",
    "            }\n",
    "    except Exception:\n",
    "        result_data = {\n",
    "        \"device_id\": device_id,\n",
    "        \"action\": action,\n",
    "        \"message\": message\n",
    "    }\n",
    "\n",
    "    return json.dumps(result_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd9cbb0",
   "metadata": {},
   "source": [
    "## TV Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "343b6b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def control_tv(device_id: str, action: powerAction) -> str:\n",
    "    \"\"\"\n",
    "    Controls a television by turning it 'on' or 'off'.\n",
    "    This tool *only* sends the 'on' or 'off' command.\n",
    "\n",
    "    Args:\n",
    "        device_id (str): The identifier for the TV (e.g., 'living_room_tv').\n",
    "        action (powerAction): The desired action, must be 'on' or 'off'.\n",
    "\n",
    "    Returns:\n",
    "        str: A JSON formatted string containing 'device_id', 'action', and a 'message'.\n",
    "    \"\"\"\n",
    "    print(f\"\\n*** TOOL WORKED: control_tv(device_id={device_id}, action={action}) ***\")\n",
    "    \n",
    "    if action == \"on\":\n",
    "        message = f\"I have turned on the {device_id}.\"\n",
    "    else:\n",
    "        message = f\"I have turned off the {device_id}.\"\n",
    "\n",
    "    payload = {\n",
    "        'device_id': device_id,\n",
    "        'action': action\n",
    "    }\n",
    "        \n",
    "    try:\n",
    "        response = requests.post(f\"{API_URL}/update_device\", json=payload)\n",
    "        if response.status_code == 200:\n",
    "\n",
    "            result_data = {\n",
    "                \"device_id\": device_id,\n",
    "                \"action\": action,\n",
    "                \"message\": message,\n",
    "                \"api_response\": \"success\"\n",
    "            }\n",
    "        else:\n",
    "            result_data = {\n",
    "                \"device_id\": device_id,\n",
    "                \"action\": action,\n",
    "                \"message\": message,\n",
    "                \"api_response\": \"failure\",\n",
    "            }\n",
    "    except Exception:\n",
    "        result_data = {\n",
    "        \"device_id\": device_id,\n",
    "        \"action\": action,\n",
    "        \"message\": message\n",
    "    }\n",
    "\n",
    "    return json.dumps(result_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f734b42a",
   "metadata": {},
   "source": [
    "## Thermostat Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3a84c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def control_thermostat(action: HvacAction) -> str:\n",
    "    \"\"\"\n",
    "    Controls the central thermostat by setting its operation mode.\n",
    "    Assumes a single, central thermostat (no device_id needed).\n",
    "\n",
    "    Args:\n",
    "        action (HvacAction): The desired mode, e.g., \"set_mode_off\", \"set_mode_on\"\n",
    "\n",
    "    Returns:\n",
    "        str: A human-readable confirmation message.\n",
    "    \"\"\"\n",
    "    print(f\"\\n*** TOOL WORKED: control_thermostat(action={action}) ***\")\n",
    "    \n",
    "    mode = action.split('_')[-1] \n",
    "    #return f\"The thermostat mode has been set to {mode}.\"\n",
    "    message = f\"I have set the thermostat mode to {mode}.\"\n",
    "\n",
    "    payload = {\n",
    "        'device_id': \"thermostat_mode\",\n",
    "        'action': action\n",
    "    }\n",
    "\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(f\"{API_URL}/update_device\", json=payload)\n",
    "        if response.status_code == 200:\n",
    "\n",
    "            result_data = {\n",
    "                \"device_id\": 'thermostat_mode',\n",
    "                \"action\": action,\n",
    "                \"message\": message,\n",
    "                \"api_response\": \"success\"\n",
    "            }\n",
    "        else:\n",
    "            result_data = {\n",
    "                \"device_id\": 'thermostat_mode',\n",
    "                \"action\": action,\n",
    "                \"message\": message,\n",
    "                \"api_response\": \"failure\",\n",
    "            }\n",
    "    except Exception:\n",
    "        result_data = {\n",
    "        \"device_id\": 'thermostat_mode',\n",
    "        \"action\": action,\n",
    "        \"message\": message\n",
    "    }\n",
    "\n",
    "    return json.dumps(result_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8f7495",
   "metadata": {},
   "source": [
    "## Water Valve Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "895e4324",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def control_water_valve(device_id: str, action: OpenCloseAction) ->str:\n",
    "    \"\"\"\n",
    "    Controls a water valve by setting it to 'open' or 'close'.\n",
    "    This tool *only* sends the command; it does not check the current state.\n",
    "\n",
    "    Args:\n",
    "        device_id (str): The identifier for the valve (e.g., 'main_water_valve').\n",
    "        action (OpenCloseAction): The desired action, must be 'open' or 'close'.\n",
    "\n",
    "    Returns:\n",
    "         str: A JSON formatted string containing 'device_id', 'action', and a 'message'.\n",
    "    \"\"\"\n",
    "    print(f\"\\n*** TOOL WORKED: control_water_valve(device_id={device_id}, action={action}) ***\")\n",
    "    \n",
    "    if action == \"open\":\n",
    "        message = f\"I have opened the {device_id}.\"\n",
    "    else:\n",
    "        message = f\"I have closed the {device_id}.\"\n",
    "\n",
    "    payload = {\n",
    "        'device_id': device_id,\n",
    "        'action': action\n",
    "    }\n",
    "        \n",
    "    try:\n",
    "        response = requests.post(f\"{API_URL}/update_device\", json=payload)\n",
    "        if response.status_code == 200:\n",
    "\n",
    "            result_data = {\n",
    "                \"device_id\": device_id,\n",
    "                \"action\": action,\n",
    "                \"message\": message,\n",
    "                \"api_response\": \"success\"\n",
    "            }\n",
    "        else:\n",
    "            result_data = {\n",
    "                \"device_id\": device_id,\n",
    "                \"action\": action,\n",
    "                \"message\": message,\n",
    "                \"api_response\": \"failure\",\n",
    "            }\n",
    "    except Exception:\n",
    "        result_data = {\n",
    "        \"device_id\": device_id,\n",
    "        \"action\": action,\n",
    "        \"message\": message\n",
    "    }\n",
    "\n",
    "    return json.dumps(result_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4127e0",
   "metadata": {},
   "source": [
    "## Unsupported Action Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f97f3de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def notify_unsupported_action(request: str, reason: str) -> str:\n",
    "    \"\"\"\n",
    "    Call this tool ONLY when the user asks for something you cannot do (e.g., make coffee, fly to moon).\n",
    "    \n",
    "    Args:\n",
    "        request (str): The action user asked for (e.g., \"make coffee\").\n",
    "        reason (str): Why you can't do it (e.g., \"I don't have a coffee machine\").\n",
    "    Returns:\n",
    "         str: A JSON formatted string containing 'device_id', 'action', and a 'message'.\n",
    "    \"\"\"\n",
    "    print(f\"⚠️ [NOTIFICATION] Cannot fulfill: {request}\")\n",
    "    \n",
    "    message = f\"I cannot {request} because {reason}.\"\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"device_id\": \"system\",\n",
    "        \"action\": \"notify\",\n",
    "        \"message\": message,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab9f7aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_system_tools = [control_light,\n",
    "    control_lock,\n",
    "    control_curtain,\n",
    "    control_tv,\n",
    "    control_thermostat,\n",
    "    control_water_valve,\n",
    "    notify_unsupported_action\n",
    "]\n",
    "home_system_llm = llm.bind_tools(home_system_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea617bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def home_system_agent(state: AgentState) -> dict:\n",
    "    \"\"\"\n",
    "    Responsible for executing immediate commands to control smart home devices.\n",
    "    \n",
    "    Trigger this agent ONLY when the user wants to change the physical state of:\n",
    "    - Lights (turn on/off)\n",
    "    - TV (turn on/off)\n",
    "    - Curtains/Blinds (open/close)\n",
    "    - Door Locks (lock/unlock)\n",
    "    - Thermostat (set mode off/on)\n",
    "    - Main Water Valve (open/close)\n",
    "\n",
    "    Capabilities:\n",
    "    - Checks the current state (HOME_DB) to avoid redundant actions.\n",
    "    - Handles predefined automation modes that affect these devices.\n",
    "    \n",
    "    Do NOT use for:\n",
    "    - Creating or editing automation rules.\n",
    "    - Updating user profile/memory.\n",
    "    \"\"\"\n",
    "    \n",
    "    light = HOME_DB[\"light\"]\n",
    "    tv = HOME_DB[\"tv\"]\n",
    "    curtain = HOME_DB[\"curtain\"]\n",
    "    door_lock = HOME_DB[\"door_lock\"]\n",
    "    thermostat_mode = HOME_DB[\"thermostat_mode\"]\n",
    "    main_water_valve = HOME_DB[\"main_water_valve\"]\n",
    "\n",
    "    rules_content = \"{}\"\n",
    "    try:\n",
    "        if os.path.exists(\"rules_operations.json\"):\n",
    "            with open(\"rules_operations.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "                operations_list = data.get(\"operations\", [])\n",
    "                formatted_modes = {}\n",
    "                for item in operations_list:\n",
    "                    name = item.get(\"operation_name\")\n",
    "                    actions = item.get(\"home_operations\", [])\n",
    "                    if name and actions:\n",
    "                        formatted_modes[name] = actions\n",
    "                if formatted_modes:\n",
    "                    rules_content = json.dumps(formatted_modes,ensure_ascii=False, indent=2)\n",
    "    except Exception as e:\n",
    "        print(f\"Home Agent Warning: Could not read rules file: {e}\")\n",
    "\n",
    "\n",
    "    system_prompt = f\"\"\"You are a precise smart home automation agent.\n",
    "\n",
    "# 1. TRUTH: CURRENT DEVICE STATE\n",
    "- Light: {light}\n",
    "- Door Lock: {door_lock}\n",
    "- Curtain: {curtain}\n",
    "- TV: {tv}\n",
    "- Thermostat Mode: {thermostat_mode}\n",
    "- Main Water Valve: {main_water_valve}\n",
    "\n",
    "# 1.5. KNOWLEDGE BASE: AUTOMATION MODES\n",
    "If the user asks for a Mode (e.g. \"Good Night\"), use these definitions:\n",
    "{rules_content}\n",
    "\n",
    "# 2. DEVICE ID MAPPING\n",
    "Use ONLY: 'light', 'door_lock', 'curtain', 'tv', 'main_thermostat', 'main_water_valve'.\n",
    "\n",
    "# 3. EXECUTION ALGORITHM (MANDATORY)\n",
    "You must process the user's request using this exact 3-step logic for EVERY device mentioned:\n",
    "\n",
    "Step 1: Identify ALL devices mentioned in the user's request.\n",
    "Step 2: For EACH device, compare \"Current State\" vs \"Desired State\":\n",
    "**YOU HAVE TO PROVE** that (Current State != Desired State) before calling any tool.\n",
    "   - IF (Current == Desired) -> **IGNORE** (Do nothing).\n",
    "   - IF (Current != Desired) -> **ADD TO QUEUE** (Call the tool).\n",
    "Step 3: Final Decision:\n",
    "   - **IF Queue has tools:** Call them immediately.\n",
    "      \n",
    "# 4. HANDLING UNSUPPORTED REQUESTS\n",
    "If a request is physically impossible (e.g., \"Make coffee\", \"Play music\"):\n",
    "- Call `notify_unsupported_action(request=..., reason=...)`.\n",
    "\n",
    "# 5. EXAMPLE LOGIC\n",
    "User: \"Turn off light (currently off) and TV (currently on).\"\n",
    "- Light: Off == Off -> Ignore.\n",
    "- TV: On != Off -> **Call control_tv(action='off').**\n",
    "Result: Only call TV tool.\n",
    "\n",
    "User Request:\"\"\"\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    executed_tool_outputs = []\n",
    "    \n",
    "    for msg in reversed(messages):\n",
    "        if isinstance(msg, ToolMessage):\n",
    "            if msg.name and \"transfer\" in msg.name: #supervisor agentin gonderdigi toolmessageyi de ev cihazlari toollarindan geldi zannediyor bunu engellemek icin ekledim.\n",
    "                break\n",
    "            executed_tool_outputs.append(msg)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    if executed_tool_outputs:\n",
    "        response_sentences = []\n",
    "\n",
    "        for tool_msg in reversed(executed_tool_outputs):\n",
    "            try:\n",
    "                content = json.loads(tool_msg.content)\n",
    "                \n",
    "                user_text = content.get(\"message\", f\"Action completed for {content.get('device_id')}.\")\n",
    "                response_sentences.append(user_text)\n",
    "\n",
    "                device_id = str(content.get(\"device_id\", \"\")).lower()\n",
    "                action = str(content.get(\"action\", \"\")).lower()\n",
    "\n",
    "                if \"set_mode_\" in action: action = action.split(\"_\")[-1]\n",
    "                if \"lock\" == action: action = \"locked\"\n",
    "                if \"unlock\" == action: action = \"unlocked\"\n",
    "                if \"close\" == action: action = \"closed\"\n",
    "                if \"open\" == action: action = \"open\"\n",
    "\n",
    "\n",
    "                update_home_db(device_id, action)\n",
    "                \n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                response_sentences.append(\"Task completed.\")\n",
    "        save_db()\n",
    "\n",
    "        final_response = \" \".join(response_sentences)\n",
    "        \n",
    "        return {\"messages\": [AIMessage(content=final_response, name=\"home_operations\")]}\n",
    "\n",
    "    \n",
    "    user_msg = next((msg.content for msg in reversed(state[\"messages\"]) if isinstance(msg, HumanMessage)),None)\n",
    "    \n",
    "    \n",
    "    if not user_msg:\n",
    "        return {\"messages\": [AIMessage(content=\"I'm ready. What can I help you with?\", name=\"home_operations\")]}\n",
    "        \n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=user_msg)\n",
    "    ]\n",
    "\n",
    "    response = home_system_llm.invoke(messages)\n",
    "\n",
    "    print(f\"home agent message: {response}\")\n",
    "    return {\n",
    "        \"messages\": [response]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8966d13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_node = ToolNode(home_system_tools)\n",
    "\n",
    "def should_continue(state: AgentState) -> str:\n",
    "    \"\"\"\n",
    "    Decides whether to continue the workflow or end it.\n",
    "    If the last AIMessage contains a tool call, continue to the tool node.\n",
    "    Otherwise, end the workflow.\n",
    "    \"\"\"\n",
    "    last_message = state[\"messages\"][-1] if state[\"messages\"] else None\n",
    "\n",
    "    if isinstance(last_message, AIMessage) and last_message.tool_calls:\n",
    "        return \"tools\"  # Continue to the tool node\n",
    "    else:\n",
    "        return END     # End the workflow\n",
    "\n",
    "    \n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"agent\", home_system_agent) \n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "workflow.add_edge(START,\"agent\") \n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\", \n",
    "        END: END         \n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "home_operations = workflow.compile(\n",
    "    name=\"home_operations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37dd7f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not connect to server. Is main.py running?\n"
     ]
    }
   ],
   "source": [
    "get_initial_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b32af2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'light': 'off', 'tv': 'off', 'curtain': 'closed', 'door_lock': 'locked', 'thermostat_mode': 'off', 'main_water_valve': 'closed'}\n",
      "home agent message: content='' additional_kwargs={'function_call': {'name': 'control_thermostat', 'arguments': '{\"action\": \"set_mode_on\"}'}} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'} id='lc_run--019b7abb-8fc3-71f2-a066-eeef1e4bbc8b-0' tool_calls=[{'name': 'control_light', 'args': {'device_id': 'light', 'action': 'on'}, 'id': '1c2ca628-51a2-402f-8974-1a59974fb892', 'type': 'tool_call'}, {'name': 'control_thermostat', 'args': {'action': 'set_mode_on'}, 'id': '5a3263f0-9793-422b-b62a-33d29d7df0c5', 'type': 'tool_call'}] usage_metadata={'input_tokens': 1595, 'output_tokens': 180, 'total_tokens': 1775, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 138}}\n",
      "\n",
      "*** TOOL WORKED: control_light(device_id=light, action=on) ***\n",
      "\n",
      "*** TOOL WORKED: control_thermostat(action=set_mode_on) ***\n",
      "Database synced to home_status.json\n",
      "I have turned on the light. I have set the thermostat mode to on.\n",
      "{'light': 'on', 'tv': 'off', 'curtain': 'closed', 'door_lock': 'locked', 'thermostat_mode': 'on', 'main_water_valve': 'closed'}\n"
     ]
    }
   ],
   "source": [
    "print(HOME_DB)\n",
    "response1 = home_operations.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Turn on the light and thermostat.\")] }\n",
    ")\n",
    "son_mesaj = response1[\"messages\"][-1]\n",
    "\n",
    "print(son_mesaj.content)\n",
    "print(HOME_DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "228f183c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not connect to server. Is main.py running?\n"
     ]
    }
   ],
   "source": [
    "get_initial_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48bde8f",
   "metadata": {},
   "source": [
    "# 2.User Memory Agent(SubAgent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98d7a9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_user_memory(user_memory_file=\"user_memory.txt\"):\n",
    "    \"\"\"\n",
    "    Belirtilen dosyadan hafızayı okur ve string olarak döndürür.\n",
    "    Hata durumunda veya dosya yoksa boş string döner.\n",
    "    \"\"\"\n",
    "    memory = \"\"\n",
    "\n",
    "    try:\n",
    "        if os.path.exists(user_memory_file):\n",
    "            with open(user_memory_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                memory = f.read()\n",
    "            print(f\"Loaded existing memory from '{user_memory_file}'.\")\n",
    "        else:\n",
    "            print(f\"'{user_memory_file}' file not found. Initializing memory as empty.\")\n",
    "            \n",
    "    except IOError as e:\n",
    "        print(f\"File read error: {e}. Initializing memory as empty.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred (reading): {e}. Initializing memory as empty.\")\n",
    "    \n",
    "    return memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3df459ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_memory(state: 'AgentState'): \n",
    "    \"\"\"\n",
    "    This agent is responsible for meticulously managing the \"CURRENT USER INFORMATION\" (user memory)\n",
    "    based on the ongoing conversation history. Its primary function is to identify, consolidate,\n",
    "    and store factual, personal, or preference-based information about the user derived from\n",
    "    their recent input.\n",
    "    \"\"\"\n",
    "    user_memory_file = \"user_memory.txt\"\n",
    "    memory = load_user_memory(user_memory_file)\n",
    "\n",
    "    memory_prompt = \"\"\"\n",
    "    You are collecting information about the user from user query and add information to \"CURRENT USER INFORMATION\"(If it exists) if there is new information about user.\n",
    "\n",
    "    CURRENT USER INFORMATION(may be empty):\n",
    "    {memory}\n",
    "\n",
    "    INSTRUCTIONS:\n",
    "    1. Review the chat history below carefully\n",
    "    2. Identify new information about the user, such as:\n",
    "        - Personal details (name, location, e.g.)\n",
    "        - Preferences (likes, dislikes)\n",
    "        - Interests and hobbies\n",
    "        - Past experiences\n",
    "    **3. Compare the identified information with the CURRENT USER INFORMATION.**\n",
    "    **4. If no new or different information is found, output the CURRENT USER INFORMATION exactly as is.**\n",
    "    **5. If new information *is* found:**\n",
    "        **a.** Merge any new information with existing memory.\n",
    "        **b.** If new information conflicts with existing memory, keep the most recent version.\n",
    "        **c.** Format the *updated* memory as a clear, bulleted list.\n",
    "\n",
    "    Important: Do NOT include summaries like \"no update needed\". Dont add your command.\n",
    "    Your response must be in text format\n",
    "    If no new data is available in user message, return the user information unmodified. Like this(may be empty):\n",
    "    {memory}\n",
    "    \"\"\"\n",
    "\n",
    "    user_msg = next((msg.content for msg in reversed(state[\"messages\"]) if isinstance(msg, HumanMessage)),None) \n",
    "\n",
    "    system_prompt = SystemMessage(content=memory_prompt.format(memory=memory))\n",
    "\n",
    "    rs = llm.invoke([system_prompt, user_msg]) \n",
    "\n",
    "    try:\n",
    "        content_to_write = str(rs.content)\n",
    "\n",
    "        with open(user_memory_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(content_to_write)\n",
    "        \n",
    "        print(f\"Success: New response was written and saved to '{user_memory_file}'.\")\n",
    "        return {\"messages\": [AIMessage(content=\"Success: New response was written and saved\", name=\"add_user_info\")]}\n",
    "\n",
    "    except IOError as e:\n",
    "        print(f\"File write error: {e}\")\n",
    "    except AttributeError:\n",
    "         print(f\"Error: Failed to get 'content' from LLM response. Response was: {rs}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred (writing): {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f9840733",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"user_memory\", user_memory)\n",
    "\n",
    "graph.add_edge(START, \"user_memory\")\n",
    "graph.add_edge(\"user_memory\", END)\n",
    "\n",
    "add_user_info = graph.compile(name=\"add_user_info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6103c696",
   "metadata": {},
   "source": [
    "The `add_user_info` subagent is designed for **user memory management**. Its sole purpose is to **review the chat history**, identify new or updated personal details, preferences, or interests shared by the user, and **update the \"CURRENT USER INFORMATION\"** accordingly.\n",
    "\n",
    "**IMPORTANT:** The supervisor agent must call `add_user_info` **only** when the user's latest query or response contains **new, non-trivial, or updated factual information** about themselves (e.g., name, location, hobby, preference). Avoid calling it for simple conversational turns, acknowledgments, or requests that don't add to the user's profile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c0bbef",
   "metadata": {},
   "source": [
    "# 3.Rule Agent(SubAgent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94608019",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OperationsSchema(BaseModel):\n",
    "    home_operations: list[Literal[\n",
    "        \"turn on light\", \"turn off light\", \n",
    "        \"turn off tv\", \"turn on tv\", \n",
    "        \"lock door\", \"unlock door\", \n",
    "        \"close curtain\", \"open curtain\", \n",
    "        \"open water valve\", \"close water valve\", \n",
    "        \"turn on thermostat\", \"turn off thermostat\"\n",
    "    ]] = Field(\n",
    "        description=\"List of specific home automation actions required for the user-defined routine. \"\n",
    "                    \"Example: For 'Define Cinema Mode as a setting that turns off the lights and turns on the TV.', map to ['turn off light', 'turn on tv'].\"\n",
    "    )\n",
    "    operation_name: str = Field(\n",
    "        description=\"The short name or trigger phrase for the operations defined by the user. \"\n",
    "                    \"Example: 'Cinema Mode' or 'Night Routine'.\"\n",
    "    )\n",
    "\n",
    "class RuleAndOperation(BaseModel):\n",
    "    rules: list[str] = Field(\n",
    "        description=\"Permanent behavioral instructions or preferences the user wants you to remember.\"\n",
    "                    \"Example: 'Always speak formally to me' or 'Always ask me for approval before opening the door.'.\",\n",
    "        default_factory=list\n",
    "    )\n",
    "    operations: Optional[OperationsSchema] = Field(\n",
    "        description=\"Schema to define a new home automation routine/macro if the user requests one.\"\n",
    "    )\n",
    "\n",
    "def rule_keeper(state: 'AgentState'): \n",
    "    \"\"\"\n",
    "    Responsible for creating, updating, or deleting automation rules and routines (macros).\n",
    "    \n",
    "    Trigger this agent ONLY when the user defines a FUTURE behavior or SCENARIO:\n",
    "    1. Defining Routines/Modes: \n",
    "       - e.g., \"Create 'Cinema Mode' that turns off lights and turns on TV.\"\n",
    "       - e.g., \"Update 'Morning Routine' to also open the curtains.\"\n",
    "    2. Setting Persistent Rules: \n",
    "       - e.g., \"Always ask for confirmation before unlocking the door.\"\n",
    "       - e.g., \"Never turn on the music after 10 PM.\"\n",
    "\n",
    "    Capabilities:\n",
    "    - Parses user intent into structured JSON (Operations & Rules).\n",
    "    - Persists data to 'rules_operations.json'.\n",
    "    - Merges new instructions with existing ones (Update/Overwrite logic).\n",
    "\n",
    "    Do NOT use for:\n",
    "    - Executing a command RIGHT NOW (e.g., \"Turn on the light\" -> use 'home_system_agent').\n",
    "    - Queries about current device status.\n",
    "    \"\"\"\n",
    "    rules_file = \"rules_operations.json\"\n",
    "\n",
    "    default_data = {\"rules\": [], \"operations\": []}\n",
    "\n",
    "    rules_data = default_data\n",
    "\n",
    "    try:\n",
    "        if os.path.exists(rules_file):\n",
    "            with open(rules_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                try:\n",
    "                    file_content = json.load(f)\n",
    "                    \n",
    "                    if file_content:\n",
    "                        rules_data = file_content\n",
    "                        print(f\"Rules Agent: Loaded existing rules from JSON.\")\n",
    "                    else:\n",
    "                        print(\"Rules Agent: JSON file is empty. Using default structure.\")\n",
    "                        \n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"Rules Agent: JSON decode error (file might be corrupted). Starting fresh.\")\n",
    "        else:\n",
    "            print(f\"Rules Agent: '{rules_file}' not found. Starting fresh.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Rules Agent: Error reading file: {e}\")\n",
    "\n",
    "    current_rules_content = json.dumps(rules_data, ensure_ascii=False, indent=2)\n",
    "        \n",
    "    system_prompt_content = \"\"\"\n",
    "    You are the \"Rule Manager\" of a smart home system. \n",
    "    Your ONLY job is to maintain a persistent record of automation rules based on user commands.\n",
    "\n",
    "    ### CURRENT DATABASE (JSON format):\n",
    "    {current_rules_content}\n",
    "\n",
    "    ### INSTRUCTIONS:\n",
    "    1. Analyze the User's Input to identify the **Trigger** (e.g., \"Cinema Mode\", \"I'm home\") and the **Actions** (e.g., \"Lights off\", \"TV on\").\n",
    "\n",
    "    2. **SEMANTIC MATCHING**\n",
    "        - Before creating a new Trigger key, look at the CURRENT DATABASE keys.\n",
    "        - If the user's trigger is semantically similar to an existing key (e.g., \"Movie Mode\" ≈ \"Cinema Mood\", \"I'm back\" ≈ \"Welcome Home\"), **USE THE EXISTING KEY**.\n",
    "\n",
    "    3. **UPDATE LOGIC:**\n",
    "        - If the Trigger is NEW: Create the entry.\n",
    "        - If the Trigger EXISTS:\n",
    "            a. **MERGE** the new actions with the existing actions.\n",
    "            b. **DEDUPLICATE:** Remove exact duplicates (e.g., do NOT allow [\"Light on\", \"Light on\"]).\n",
    "            c. **RESOLVE CONFLICTS:** If a NEW action conflicts with an OLD action (e.g., Old: \"Light On\", New: \"Light Off\"), the **NEW action overwrites** the old one.\n",
    "            d. **CONTEXT AWARENESS:** If the user phrase implies a full definition (e.g., \"When I say X, do A, B and C\"), ensure the final list reflects exactly A, B, and C. Remove unrelated old actions if they seem contradictory to the new definition.\n",
    "        \n",
    "    4. **OUTPUT FORMAT:**\n",
    "        - Output ONLY the updated JSON string. \n",
    "        - No markdown, no conversation, no explanations.\n",
    "        - If the user input is unclear, return the CURRENT DATABASE unchanged.\n",
    "\n",
    "    ### EXAMPLE:\n",
    "    Current: {{\"cinema mode\": [\"lights off\", \"tv on\"]}}\n",
    "    User: \"For cinema mode, also close the curtains\"\n",
    "    Output: {{\"cinema mode\": [\"lights off\", \"tv on\", \"close the curtains\"]}}\n",
    "\n",
    "    Current: {{\"sleep mode\": [\"lights on\"]}}\n",
    "    User: \"Change sleep mode to turn lights off\"\n",
    "    Output: {{\"sleep mode\": [\"lights off\"]}}\n",
    "    \"\"\"\n",
    "\n",
    "    user_msg = next((msg.content for msg in reversed(state[\"messages\"]) if isinstance(msg, HumanMessage)), None)\n",
    "    if not user_msg:\n",
    "        return {\"messages\": [AIMessage(content=\"No user message found to process.\")]}\n",
    "\n",
    "\n",
    "    structured_llm = llm.with_structured_output(RuleAndOperation)\n",
    "\n",
    "    system_prompt = SystemMessage(content=system_prompt_content.format(current_rules_content=current_rules_content))\n",
    "\n",
    "    messages = [\n",
    "        system_prompt,\n",
    "        HumanMessage(content=user_msg)\n",
    "    ]\n",
    "\n",
    "    response_obj = structured_llm.invoke(messages)\n",
    "\n",
    "\n",
    "    rules_file = \"rules_operations.json\" \n",
    "\n",
    "    if os.path.exists(rules_file):\n",
    "        try:\n",
    "            with open(rules_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                current_data = json.load(f)\n",
    "        except json.JSONDecodeError:\n",
    "            current_data = {\"rules\": [], \"operations\": []}\n",
    "    else:\n",
    "        current_data = {\"rules\": [], \"operations\": []}\n",
    "\n",
    "    # Key garantisi\n",
    "    if \"rules\" not in current_data: current_data[\"rules\"] = []\n",
    "    if \"operations\" not in current_data: current_data[\"operations\"] = []\n",
    "\n",
    "    changes_log = []\n",
    "\n",
    "    if response_obj.rules:\n",
    "        added_count = 0\n",
    "        for new_rule in response_obj.rules:\n",
    "            if new_rule not in current_data[\"rules\"]:\n",
    "                current_data[\"rules\"].append(new_rule)\n",
    "                added_count += 1\n",
    "        \n",
    "        if added_count > 0:\n",
    "            changes_log.append(f\"Added {added_count} new rules.\")\n",
    "\n",
    "    if response_obj.operations:\n",
    "        new_op_data = response_obj.operations.model_dump()\n",
    "        new_op_name = new_op_data.get(\"operation_name\")\n",
    "        \n",
    "        found_index = -1\n",
    "        for i, existing_op in enumerate(current_data[\"operations\"]):\n",
    "            if existing_op.get(\"operation_name\") == new_op_name:\n",
    "                found_index = i\n",
    "                break\n",
    "        \n",
    "        if found_index != -1:\n",
    "            current_data[\"operations\"][found_index] = new_op_data\n",
    "            changes_log.append(f\"Updated existing operation: '{new_op_name}'\")\n",
    "        else:\n",
    "            current_data[\"operations\"].append(new_op_data)\n",
    "            changes_log.append(f\"Created new operation: '{new_op_name}'\")\n",
    "\n",
    "    try:\n",
    "        if changes_log:\n",
    "            confirmation_msg = f\"[SYSTEM_REPORT] Database updated successfully. {' '.join(changes_log)}\"\n",
    "            with open(rules_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(current_data, f, ensure_ascii=False, indent=4)\n",
    "        else:\n",
    "            confirmation_msg = f\"[SYSTEM_REPORT] No new changes detected. The operation '{new_op_name}' already exists with these settings.\"\n",
    "            \n",
    "        print(f\"Rules Agent: {confirmation_msg}\")\n",
    "        \n",
    "        return {\"messages\": [AIMessage(content=confirmation_msg, name=\"rule_operations\")]}\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = f\"[SYSTEM_REPORT] File write error: {e}\"\n",
    "        print(f\"Rules Agent Error: {e}\")\n",
    "        return {\"messages\": [AIMessage(content=error_msg, name=\"rule_operations\")]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31bb97fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_rule = StateGraph(AgentState)\n",
    "\n",
    "graph_rule.add_node(\"keep_user_rules\", rule_keeper)\n",
    "\n",
    "graph_rule.add_edge(START, \"keep_user_rules\")\n",
    "graph_rule.add_edge(\"keep_user_rules\", END)\n",
    "\n",
    "rule_operations = graph_rule.compile(name=\"rule_operations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74bbaad",
   "metadata": {},
   "source": [
    "kolay ve guzel gorunecek bir sekilde test etmek icin fonskiyon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07354732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(str_input, agentt):\n",
    "    inputs = {\"messages\": [HumanMessage(content=str_input)]}\n",
    "    try:\n",
    "        # Recursion limit: Avoids infinite loops\n",
    "        for s in agentt.stream(inputs, config={\"recursion_limit\": 7}):\n",
    "            for agent_name, output in s.items():\n",
    "                print(f\"--- 🤖 {agent_name} ---\")\n",
    "\n",
    "                # Print the supervisor's decision\n",
    "                if \"next\" in output:\n",
    "                    print(f\"🔀 Rota: {output['next']}\")\n",
    "\n",
    "                # Print message content if available\n",
    "                if \"messages\" in output:\n",
    "                    last_msg = output[\"messages\"][-1]\n",
    "                    if isinstance(last_msg, SystemMessage):\n",
    "                        continue\n",
    "                    \n",
    "                    if hasattr(last_msg, 'content') and last_msg.content:\n",
    "                        print(f\"💬 Message: {last_msg.content}\")\n",
    "\n",
    "                    # If tool usage is present, provide details\n",
    "                    if hasattr(last_msg, 'tool_calls') and len(last_msg.tool_calls) > 0:\n",
    "                        print(f\"🛠️ Tool: {last_msg.tool_calls[0]['name']}\")\n",
    "                        print(f\"📝 Args: {last_msg.tool_calls[0]['args']}\")\n",
    "\n",
    "                print(\"------------------------------\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"🛑 An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8366df86",
   "metadata": {},
   "source": [
    "# SUPERVISOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b0f2f8",
   "metadata": {},
   "source": [
    "## Weather Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1979d1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_weather() -> str:\n",
    "    \"\"\"\n",
    "    Hava durumu bilgisini getirir.\n",
    "    WMO kodlarını insan diline çevirerek döndürür.\n",
    "    \"\"\"\n",
    "    city_name=\"Aydın\"\n",
    "\n",
    "    wmo_codes = {\n",
    "        0: \"Açık/Güneşli\",\n",
    "        1: \"Çoğunlukla Açık\",\n",
    "        2: \"Parçalı Bulutlu\",\n",
    "        3: \"Kapalı\",\n",
    "        45: \"Sisli\",\n",
    "        48: \"Kırağı/Sis\",\n",
    "        51: \"Hafif Çiseleme\",\n",
    "        53: \"Çiseleme\",\n",
    "        55: \"Yoğun Çiseleme\",\n",
    "        61: \"Hafif Yağmurlu\",\n",
    "        63: \"Yağmurlu\",\n",
    "        65: \"Şiddetli Yağmur\",\n",
    "        71: \"Hafif Kar Yağışlı\",\n",
    "        73: \"Kar Yağışlı\",\n",
    "        75: \"Yoğun Kar Yağışlı\",\n",
    "        77: \"Kar Taneleri\",\n",
    "        80: \"Hafif Sağanak\",\n",
    "        81: \"Sağanak\",\n",
    "        82: \"Şiddetli Sağanak\",\n",
    "        95: \"Fırtına/Gök Gürültülü\",\n",
    "        96: \"Dolu ve Fırtına\",\n",
    "        99: \"Şiddetli Dolu ve Fırtına\"\n",
    "    }\n",
    "\n",
    "    geo_url = \"https://geocoding-api.open-meteo.com/v1/search\"\n",
    "    geo_params = {\"name\": city_name, \"count\": 1, \"language\": \"tr\", \"format\": \"json\"}\n",
    "    \n",
    "    try:\n",
    "        geo_response = requests.get(geo_url, params=geo_params)\n",
    "        geo_response.raise_for_status()\n",
    "        geo_data = geo_response.json()\n",
    "        \n",
    "        if not geo_data.get(\"results\"):\n",
    "            return f\"Hata: '{city_name}' bulunamadı.\"\n",
    "            \n",
    "        location = geo_data[\"results\"][0]\n",
    "        lat = location[\"latitude\"]\n",
    "        lon = location[\"longitude\"]\n",
    "        place_name = f\"{location['name']}, {location.get('country', '')}\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Hata (Konum): {str(e)}\"\n",
    "\n",
    "    weather_url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "    weather_params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"current_weather\": \"true\",\n",
    "        \"timezone\": \"auto\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        w_response = requests.get(weather_url, params=weather_params)\n",
    "        w_response.raise_for_status()\n",
    "        w_data = w_response.json()\n",
    "        \n",
    "        current = w_data.get(\"current_weather\", {})\n",
    "        code = current.get('weathercode')\n",
    "        \n",
    "        condition_text = wmo_codes.get(code, \"Bilinmiyor\")\n",
    "        \n",
    "        result = {\n",
    "            \"konum\": place_name,\n",
    "            \"sicaklik\": f\"{current.get('temperature')}°C\",\n",
    "            \"ruzgar\": f\"{current.get('windspeed')} km/h\",\n",
    "            \"durum\": condition_text,  \n",
    "        }\n",
    "        \n",
    "        return str(result)\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Hata (Hava Durumu): {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c1d5690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_template = \"\"\"\n",
    "You are a helpful Home Assistant Supervisor coordinating three specialists:\n",
    "- **add_user_info**: saves NEW, long-term facts about the user (e.g., name, location, hobbies).\n",
    "- **home_operations**: controls physical devices (lights, TV, curtain, door, thermostat, water valve). Examples: \"Turn on lights\", \"Turn off tv\".\n",
    "- **rule_operations**: defines, updates, or deletes FUTURE automation rules or scenarios.\n",
    "\n",
    "Your goal is to satisfy the user’s intent with minimal steps, avoiding unnecessary agent calls.\n",
    "\n",
    "Context Data:\n",
    "<user_memory>\n",
    "{memory}\n",
    "</user_memory>\n",
    "\n",
    "<active_rules_and_ops>\n",
    "{rule_and_operations}\n",
    "</active_rules_and_ops>\n",
    "\n",
    "Routing:\n",
    "- If the user shares NEW factual info not already in `<user_memory>`, use `add_user_info`.\n",
    "- If the user wants to control a device use `home_operations`(e.g. \"Turn on lights\", \"Turn on tv\"). \n",
    "- If the user wants to triggers an operation explicitly listed in `<active_rules_and_ops>`, use `home_operations`.\n",
    "- If the user defines or edits logic for the FUTURE (e.g., \"Create a mode\", \"Always do X when Y\") or the user defines a new operation sequence or alias (e.g., \"If I say 'Dark Mode', turn off the lights\", \"Define 'Cinema Mode' as closing curtains and turning on the TV\"), use `rule_operations`.\n",
    "- If the input is a greeting, general question, or simple acknowledgment, **DO NOT use tools**; reply directly using the context.\n",
    "\n",
    "Guardrails:\n",
    "- **Memory Check:** Do not use `add_user_info` for temporary states (e.g., \"I am hungry\") or information already present in memory.\n",
    "- **Execution vs. Definition:** Distinguish clearly. \"Turn on Cinema Mode\" is `home_operations` (execution). \"Define Cinema Mode\" is `rule_operations` (definition).\n",
    "- **Personalization:** Always check `<user_memory>` to tailor your response and adhere to any interaction rules in `<active_rules_and_ops>`.\n",
    "- **Weather Tool Usage:** Invoke the `get_weather` tool not only for direct inquiries but also when the user implies outdoor context (e.g., 'I am going out,', 'I will walk to school.'). Use the retrieved data to provide proactive recommendations or safety advice.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f56a214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_formatted_rules_and_operations(file_path=\"rules_operations.json\"):\n",
    "    \"\"\"\n",
    "    Belirtilen JSON dosyasından kuralları ve operasyonları okuyup\n",
    "    okunaklı bir string formatında döndürür.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        return \"Rules Agent: Dosya bulunamadı, henüz kural veya operasyon yok.\"\n",
    "\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "        output_lines = []\n",
    "\n",
    "        # --- RULES ---\n",
    "        output_lines.append(\"RULES:\")\n",
    "        rules = data.get(\"rules\", [])\n",
    "        \n",
    "        if rules:\n",
    "            for rule in rules:\n",
    "                output_lines.append(f\"- {rule}\")\n",
    "        else:\n",
    "            output_lines.append(\"- (Kayıtlı kural yok)\")\n",
    "\n",
    "        output_lines.append(\"\") \n",
    "\n",
    "        # --- OPERATIONS ---                Bence bunu buraya kullanmaya gerek yok. zatem home operations agenti bunu kullaniyor.\n",
    "        output_lines.append(\"OPERATIONS:\")\n",
    "        operations = data.get(\"operations\", [])\n",
    "        \n",
    "        if operations:\n",
    "            for op in operations:\n",
    "                name = op.get(\"operation_name\", \"Bilinmeyen Operasyon\")\n",
    "                actions_list = op.get(\"home_operations\", [])\n",
    "                actions_str = \", \".join(actions_list)\n",
    "                \n",
    "                output_lines.append(f\"- {name} : {actions_str}\")\n",
    "        else:\n",
    "            output_lines.append(\"- (Kayıtlı operasyon yok)\")\n",
    "\n",
    "        return \"\\n\".join(output_lines)\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        return \"Rules Agent: Dosya formatı bozuk (JSON Hatası).\"\n",
    "    except Exception as e:\n",
    "        return f\"Rules Agent: Bir hata oluştu: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f11e9093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def supervisor_context_node(state: AgentState):\n",
    "\n",
    "    current_memory = load_user_memory()\n",
    "    current_rules = get_formatted_rules_and_operations()\n",
    "\n",
    "    dynamic_content = sup_template.format(\n",
    "        memory=current_memory, \n",
    "        rule_and_operations=current_rules\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [SystemMessage(content=dynamic_content)]\n",
    "    }\n",
    "\n",
    "supervisor = create_supervisor(\n",
    "    agents=[add_user_info, home_operations, rule_operations],\n",
    "    model=llm,\n",
    "    tools=[get_weather],\n",
    "    prompt=\"You are a smart home supervisor. Follow the instructions provided in the system context.\",\n",
    "    add_handoff_back_messages=True,\n",
    "    output_mode=\"full_history\"\n",
    ")\n",
    "\n",
    "builder = StateGraph(AgentState)\n",
    "\n",
    "builder.add_node(\"refresh_context\", supervisor_context_node)\n",
    "builder.add_node(\"supervisor\", supervisor.compile()) \n",
    "\n",
    "builder.add_edge(START, \"refresh_context\")\n",
    "builder.add_edge(\"refresh_context\", \"supervisor\")\n",
    "builder.add_edge(\"supervisor\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5036d940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing memory from 'user_memory.txt'.\n",
      "--- 🤖 refresh_context ---\n",
      "Rules Agent: Loaded existing rules from JSON.\n",
      "Rules Agent: [SYSTEM_REPORT] Database updated successfully. Created new operation: 'Movie Time'\n",
      "--- 🤖 supervisor ---\n",
      "💬 Message: [{'type': 'text', 'text': \"Alright, Sadık. I've set up 'Movie Time' for you. When you say 'Movie Time', I will turn off the lights, turn on the TV, close the curtains, and lock the door.\", 'extras': {'signature': 'Cu0EAXLI2nwGLwClyse36aNT4ZN9Cv9qYZmq1iCmArVJ76ruIfPxd3ssjdtwBgH6SW8voizxKFMgIzQ/FETPxTfQH313q37ft1cEVkQv7Ye3+OxYQWzGTWkVWwdTMIWTYGTPgllOzLsSMfwIwl05ymA9PZXozgIlya/ZK7Nm+DLalTSyOg/ShPMglBPU6QXM9WVGqQgyl2RajNb+iXnjFn6SqloMhZs+zjA+UOY5ll3dv/OFZ5n8Xdq5kZ9G7gza5T8u4UR5DVNDbOdr+1RT38sg4zFVQkqlZxe+3sJ9etqJXrtdgVnSC6cBIbYCZhE0TZC1OGIvxw5xvv4PY9JGCJZeQNqZge7XPyTHTxRKQVwaOuilQxGrAz5I/DPqHzdsqH9gvcgMo629NFam+szDFOGJ5PwSps1OFvDY0eRX3eDg+aks1ftydUTz7WfhxfDCXRN2nhHhGzqG+ft0CXAAxoh6bUL5KsR0omIAKUT3siC85vGQfnu2GOSWSYBA4E+BLtOiqSHz0DaMV3DXMTmj2iQWvW6Ti9LRA4jxA3tR907UxPtCVZjEpavR2lFi+1FykMjMuAywQ4l4V3ap1Dcy+XJ0KOnMF3Qy10DLeOqb38WXtrTRB4r/u1jBqaMb8/13p2up6XsIXf8AK9fWW9p5ASC0WQl/dHTmLMu+ZTwKsPtCWbbGr8sbh94MhfruSFcLfOV6quj26noEG2yNuBvrc+SwoGGkd7OVbnLffNvMTFmYZ3Dp6C/Fp7VvIHmCoKBvtzVzr851hRrc9BMW27X2UXgWzh9kwJ1SBg+r9eLSkfqLC1jNO18HOxX3lcEXbern'}}]\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_query(\"when i say 'Movie Time', turn off the lights and turn on the tv, close the curtains and lock the door.\", graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "263d9a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing memory from 'user_memory.txt'.\n",
      "--- 🤖 refresh_context ---\n",
      "--- 🤖 supervisor ---\n",
      "💬 Message: [{'type': 'text', 'text': 'Thank you for letting me know. I will make sure to say thank you every time I answer you.', 'extras': {'signature': 'CqgDAXLI2nwXHthD9HwwxDki2eizo0Ydo+1ffF6Id1b44EboqIIWgPIa/wCmz4DsfAZaWE7tPaWLt5yXcy1/XLPSeuDj4Ds1zYLctfAdInMwnP01x6oRVPgjutaPz4HBZ8CC5nw5XAMiPm4xgrcoNX6MJvcZGcTXn9yQoiPjuf38KX16iM6Sc5TAdMpZ3xYJc5L+6yAwJahlTHVzaNOglje6noCvYNYUOJKgx6oA4DbrJqntC4FEUL4DKl8aeeWrrudQGLJ8TPnTP3OhKcw5Yzq8L8WrAmiYTpqMkxYT8RR4FZrWuMPa3aE70heU5d+3qGCfqDl398p9F7RLD7L/WYJ3Gq/w1yIbxx6FQ0DEM+GRt9jUCrGvKbMwMQG49FyLflKSiPlnVhMUQKKyXzDcu5+8DA5XEX6CWn7zN3BKy3kBh+sgCWc2GHHxY/DvcHP99HKeqioH46ku+7XJSwhFMXTvopF2snxxpc8hCxHnK9gL4zkkIzzT44m7zYTO/fgK2j56bxIJuveaFHdT89jf6NL3pgdQOHoFCnvcUr/udZA657LAgxKDiuHxUg=='}}]\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_query(\"Say thank you every time you answer me.\", graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "407cfb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing memory from 'user_memory.txt'.\n",
      "--- 🤖 refresh_context ---\n",
      "Rules Agent: Loaded existing rules from JSON.\n",
      "Rules Agent: [SYSTEM_REPORT] Database updated successfully. Added 1 new rules.\n",
      "--- 🤖 supervisor ---\n",
      "💬 Message: Thank you for the instruction! I will make sure to say thank you every time I answer you from now on.\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_query(\"Say thank you every time you answer me. Use rule_operations \", graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0612be48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing memory from 'user_memory.txt'.\n",
      "--- 🤖 refresh_context ---\n",
      "Loaded existing memory from 'user_memory.txt'.\n",
      "Success: New response was written and saved to 'user_memory.txt'.\n",
      "--- 🤖 supervisor ---\n",
      "💬 Message: Alright, I'll make sure to address you like my older brother from now on, Sadık. What can I do for you, big bro?\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_query(\"Always answer me as if I were your older brother.\", graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6bcea1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing memory from 'user_memory.txt'.\n",
      "--- 🤖 refresh_context ---\n",
      "--- 🤖 supervisor ---\n",
      "💬 Message: [{'type': 'text', 'text': \"Hello! I'm functioning well, thank you. How can I help you today, Sadık?\", 'extras': {'signature': 'Cr4BAXLI2nzubUFEH6XVzSb4FicYeRu9+sNq+3NkzlvGNRI6g7dhUu2dE0RTs3oGd1NdlmU1xX5mK7Iwo07IicmnemyuaUwklqW6X4sLZ0hOuRk5Czl9/8TxkKZOl1NnN+Tb2uobHS3gOsALazcAdiBXPQQXpzY6BzWhAYNdLL+SBEwHPGPMDTWq3dqVeb+F3j9C73i7vOjrtRedUuoqMyqhaQx+H9QYoxxYSci3lnXdHcN7RKPovXuSDGF1TTL5LA=='}}]\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_query(\"Hi how are you?\", graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29e33d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing memory from 'user_memory.txt'.\n",
      "--- 🤖 refresh_context ---\n",
      "Loaded existing memory from 'user_memory.txt'.\n",
      "Success: New response was written and saved to 'user_memory.txt'.\n",
      "--- 🤖 supervisor ---\n",
      "💬 Message: [{'type': 'text', 'text': \"Hello John! It's great to learn more about you. I've noted that your name is John and you love hiking and photography. Is there anything else I can help you with today?\", 'extras': {'signature': 'CtsCAXLI2nw85N2NxWrHJe1DtDLidhcfMzKst8C+vPeuaXnYTdpRrFBMnYPFVnGni0LeXz9e4qi5UF6uMRgSGqb00LOAAdW890hYgdGc2UW9of+5zL/1B7HAZNdxuVvr8s2EmpKx9XOec7GgGOQ5iX9Un1DOt6E34pwzSon0gZq6HSeDWd4DVOWQU7+meJTkmN6ERcHsSu4zjc7enqMXu6zuubNG7Th0cDQ8ghjPfTjF8UOdih/l7nN8tpcEuwJZULSPK9xvROT5SjTLRMNL99GyuEfaC+uMNs5rib5ihCNX2ZKPg2AkpSzfHAD+ssCwiPodaK5PN/PpLLmyCfOr3x5fUzQNj2CXhboEDOcx8Du6rSGXnTIbXQ9HdEuGwCI566ZXH9Nw5yrJerM5xUIbpGsZOWdNkP9YG3Wox7h+BEgo/LWL2s7i3CgZRSzFeLdxDoVfAKl5pZ6ccsFyeE8='}}]\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_query(\"My name is John and I love hiking and photography.\", graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3492774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing memory from 'user_memory.txt'.\n",
      "--- 🤖 refresh_context ---\n",
      "--- 🤖 supervisor ---\n",
      "💬 Message: [{'type': 'text', 'text': 'I understand! I will always do my best to answer you kindly and politely. How can I help you today?', 'extras': {'signature': 'CvoCAXLI2nwZ6m/wWHVEF2O5dUyU5Tz7SJSzIWdBeNJC6rgSWxRFEc5QsqgddjkWKNKQ476vSoqIZfa2488UwnuGi1cS6NpPcg2wDHuFZZ97MXjel2/GQObqFLFyudhsMdM9E+wn17K+TlXW4qf5iMFD8yaFCPNR3xa41wDNhTAGIYFK3ZsnwV6EVcNauHxG+kAz8a1jd8AU+w9Hsk6h2V4c4h7wgYqSzKR+ZCmp807T/OTKxLRN0yKXNmsQBll/bBgtfJgW+rppM9JtjIXaP8PLkAnoFKRM2cQ0fV0nxmfBkMhiS3RKjidZ1OO+A1h/ZI9U80/UBe9P8he8uadTUsxgtEJXXIpVuxcTf9CA9hQ5byJUaxkYkmDde6oSlgTZPkG5aG1dd4hXxwHhNrMadALNiuxIscMEbH1ipARsmrHDPkfBKj/KyNB5242ylUJEW8qn1pNGWYugM977A9+w/iQ8WIA7Z0XtoPC+CmKFBZvfQyhMUS9JQQEGyRKu'}}]\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_query(\"always answer me kindly and politely.\", graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2eada43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing memory from 'user_memory.txt'.\n",
      "--- 🤖 refresh_context ---\n",
      "Loaded existing memory from 'user_memory.txt'.\n",
      "Success: New response was written and saved to 'user_memory.txt'.\n",
      "--- 🤖 supervisor ---\n",
      "💬 Message: [{'type': 'text', 'text': \"Thank you for sharing, Sadık! I've noted that your age is 23. Is there anything else I can help you with?\", 'extras': {'signature': 'CvcDAXLI2nw/PaYpCvC/EksbR3gW3l3pqgg6RIiOFIZSgompdWUpmgOJQYTrxdOrpL5O1O3H+bcCrFsJ3v9xG+eInwfaKg1yKzFusFb7ZaazUZVt1iYLJ1SSIvHJwktDtmfNXxhEcSCdWXn9qPdm7neFsMBqPlxb6AiHJYMCmGDOZellLE4FF9w4PjWMD88mD/se/xH0gCyxA7s/OJSqBdxp4qZBavqeJUmBnPuhUzYkdHsNGKXxVFf5Nxrp6vFc6d3yw3jBFMood7mUmPYnJbfF5nEj5HptVyb6/aUZuNE47kqG+rBVxkSmwVC26jN0enzVAaiMmzA+hKpKeyRqGslxib2xD5cTxPRNAI90OBBDW2KhkdnGkKDp10iqsbt6+6AOOclHtKRpa+L7SnCAzc2SKg1o1cpgOGlo5DXaLmetgDzuJGMYTCJRsBaOcSI0h5CLManY26DJr/p7/e/Cc2pPmhonnw71+s0mR7RUVTe+u1izIgUEfWte0L21XR6j2q7c7RIE5wZtlGC9ul1iiehxEYlJCx6SK+CDG85eGoTU+uL2DnHUMsDg/G0Z4/pYhY/U/whRiUJarxrMHkalMLe+hLX6N7SFW6Ya/1J/m4eznxemMNA6oSlIbn1/onNoY4VPbOi49/spRa4Xb2cUlqqhh/GsRwEd788='}}]\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_query(\"My age is 23\", graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0253d292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'light': 'off', 'tv': 'off', 'curtain': 'closed', 'door_lock': 'locked', 'thermostat_mode': 'off', 'main_water_valve': 'closed'}\n"
     ]
    }
   ],
   "source": [
    "print(HOME_DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d782a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing memory from 'user_memory.txt'.\n",
      "--- 🤖 refresh_context ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\n",
      "Please retry in 28.902151173s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 28\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\n",
      "Please retry in 26.74717124s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\n",
      "Please retry in 22.602027621s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\n",
      "Please retry in 14.445252716s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 14\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\n",
      "Please retry in 58.278617334s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 58\n",
      "}\n",
      "].\n"
     ]
    }
   ],
   "source": [
    "run_query(\"It's getting dark, turn on the light and open the curtains. turn on the tv and cook for me please\", graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fb9ee242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing memory from 'user_memory.txt'.\n",
      "--- 🤖 refresh_context ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\n",
      "Please retry in 37.138705795s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 37\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\n",
      "Please retry in 34.979954746s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 34\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\n",
      "Please retry in 30.834074739s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 30\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\n",
      "Please retry in 22.685931524s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\n",
      "Please retry in 6.456070063s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 6\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🛑 An error occurred: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\n",
      "Please retry in 34.303304643s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 20\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 34\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "run_query(\"It's getting dark, turn on the light and close the curtains. turn on the tv and order food please\", graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cca01d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
